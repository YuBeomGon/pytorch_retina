{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "requested-contractor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from retinanet import coco_eval\n",
    "from retinanet import csv_eval\n",
    "from retinanet import model\n",
    "from retinanet import paps_eval\n",
    "from retinanet import paps_train\n",
    "\n",
    "# from retinanet import retina\n",
    "from retinanet.dataloader import *\n",
    "from retinanet.anchors import Anchors\n",
    "from retinanet.anchors import *\n",
    "from retinanet.losses import *\n",
    "from retinanet.scheduler import *\n",
    "from retinanet.hourglass import hg1, hg2, hg8\n",
    "from retinanet.parallel import DataParallelModel, DataParallelCriterion\n",
    "\n",
    "#Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "from torch.optim import Adam, lr_scheduler\n",
    "import torch.optim as optim\n",
    "\n",
    "# python train_paps.py --start_epoch 0 --end_epoch 120 --batch_size 24 \\\n",
    "#                     --saved_dir $OUT_MODEL_DIR --gpu_num 0 --num_workers 12 \\\n",
    "#                     --target_threshold 7 --topk 20 --filter_option 1  | 2>&1 | tee $log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ultimate-intake",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes 2\n",
      "num_anchors per feature map 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HourglassNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (hg): ModuleList(\n",
       "    (0): Hourglass(\n",
       "      (hg): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (3): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): Hourglass(\n",
       "      (hg): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (3): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (anchors): Anchors()\n",
       "  (regressionModel): RegressionModel(\n",
       "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (act1): ReLU()\n",
       "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (act2): ReLU()\n",
       "    (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (act3): ReLU()\n",
       "    (conv4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (act4): ReLU()\n",
       "    (output): Conv2d(256, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (classificationModel): ClassificationModel(\n",
       "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (act1): ReLU()\n",
       "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (act2): ReLU()\n",
       "    (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (act3): ReLU()\n",
       "    (conv4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (act4): ReLU()\n",
       "    (output): Conv2d(256, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (output_act): Sigmoid()\n",
       "  )\n",
       "  (regressBoxes): BBoxTransform()\n",
       "  (clipBoxes): ClipBoxes()\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device = torch.device('cpu')\n",
    "# device = torch.device('cuda')\n",
    "GPU_NUM = 0 # 원하는 GPU 번호 입력\n",
    "device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "model = hg2(device, pretrained=True, progress=False, num_classes=2)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "excessive-sound",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "greenhouse-methodology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.48s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# train_info = np.load('../data/train.npy', allow_pickle=True, encoding='latin1').item()\n",
    "# train_info\n",
    "\n",
    "batch_size = 1\n",
    "dataset_train = PapsDataset('../data/', set_name='train_2class',\n",
    "                            transform=train_transforms)\n",
    "\n",
    "train_data_loader = DataLoader(\n",
    "    dataset_train,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=12,\n",
    "    pin_memory=True,\n",
    "    prefetch_factor=1,\n",
    "    collate_fn=collate_fn\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "minor-rider",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = PapsLoss(device, target_threshold=8, topk=10, filter_option=6)\n",
    "criterion = criterion.to(device)\n",
    "model.training = True\n",
    "\n",
    "# https://gaussian37.github.io/dl-pytorch-lr_scheduler/\n",
    "optimizer = optim.Adam(model.parameters(), lr = 1e-8)\n",
    "scheduler = CosineAnnealingWarmUpRestarts(optimizer, T_0=20, T_mult=2, eta_max=0.0008,  T_up=5, gamma=0.5)\n",
    "# CosineAnnealingWarmRestarts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "greenhouse-practitioner",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_dir = '../trained_models/HourGlass/loss_image_filter' + str(0) + '/'\n",
    "s_epoch= 0\n",
    "e_epoch= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "searching-safety",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir(saved_dir) == False :\n",
    "    print('folder is made')\n",
    "    os.makedirs(saved_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "hispanic-rings",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(saved_dir + 'epoch_' + str(e_epoch) +'_model.pt') :\n",
    "    print('pretrainind file loading')\n",
    "    state = torch.load(saved_dir + 'epoch_' + str(e_epoch) +'_model.pt')\n",
    "    epoch = state['epoch']\n",
    "    model.load_state_dict(state['state_dict'], strict=False)\n",
    "    optimizer.load_state_dict(state['optimizer'])\n",
    "    last_loss = state['loss']\n",
    "else :\n",
    "    last_loss = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4875717-7a4a-45ab-b061-1579773f67ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = images.cpu()\n",
    "# images = [torchvision.transforms.ToPILImage()(x) for x in images]\n",
    "# images = [torchvision.transforms.Grayscale()(x) for x in images]\n",
    "# images = [torchvision.transforms.ToTensor()(x) for x in images]\n",
    "# images = torch.stack(images).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac417c73-9011-4b07-865b-6cc0bd910f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 3206/14874 [07:59<30:24,  6.40it/s, avg_loss=0.916, batch_loss=1, cls_loss=0.988, lr=1e-8, num_det=tensor(11, device='cuda:0'), reg_loss=0.0118]       "
     ]
    }
   ],
   "source": [
    "if s_epoch == 0:\n",
    "    Iou_low = [0.2]\n",
    "    beta_list = [1.0]\n",
    "    for i in range(1, e_epoch+1) :\n",
    "        Iou_low.append(Iou_low[0] + (0.5-0.2)*i/160)\n",
    "        beta_list.append(beta_list[0] - (1.0-0.5)*i/160)   \n",
    "\n",
    "loss_per_epoch = last_loss\n",
    "cls_loss = []\n",
    "box_loss = []\n",
    "for epoch in range(s_epoch, e_epoch) :\n",
    "    total_loss = 0\n",
    "    tk0 = tqdm(train_data_loader, total=len(train_data_loader), leave=False)\n",
    "    EPOCH_LEARING_RATE = optimizer.param_groups[0][\"lr\"]\n",
    "    foreground_class = []\n",
    "    background_class = []\n",
    "\n",
    "    for step, data in enumerate(tk0) :\n",
    "        if step > len(train_data_loader)/2 and epoch%10 > 0 :\n",
    "#             if step > len(train_data_loader)/4 :\n",
    "            break \n",
    "        if s_epoch == 0 :\n",
    "            iou_thres = np.random.uniform(low=Iou_low[epoch], high=0.5, size=None)\n",
    "            beta = np.random.uniform(low=beta_list[epoch]-0.1, high=beta_list[epoch], size=None)\n",
    "        else :\n",
    "            iou_thres = 0.5\n",
    "            beta = 0.5\n",
    "        images, box, label, targets = data\n",
    "        batch_size = len(images)\n",
    "#         pimages = images.cpu()\n",
    "#         print(pimages.shape)\n",
    "\n",
    "        c, h, w = images[0].shape\n",
    "        pimages = PyramidImages()(images).to(device)\n",
    "        images = torch.cat(images).view(-1, c, h, w).to(device)\n",
    "        targets = [ t.to(device) for t in targets]\n",
    "\n",
    "        outputs = model([images, targets])\n",
    "        \n",
    "        \n",
    "#         print(pimages.shape)\n",
    "        \n",
    "        classification, regression, anchors, _ = (outputs)\n",
    "        \n",
    "        classification_loss, regression_loss, num_det, back_c, fore_c = criterion(classification, regression, \n",
    "                                                         anchors, targets, iou_thres,\n",
    "                                                         beta, pimages=pimages)\n",
    "#         print(fore_c)\n",
    "        foreground_class.extend(fore_c)\n",
    "        background_class.extend(back_c)\n",
    "\n",
    "        classification_loss = classification_loss.mean()\n",
    "        regression_loss = regression_loss.mean()\n",
    "        loss = classification_loss + regression_loss \n",
    "        total_loss += loss.item()\n",
    "        cls_loss.append(classification_loss.item())\n",
    "        box_loss.append(regression_loss.item())\n",
    "\n",
    "        if step % 1 == 0:\n",
    "            tk0.set_postfix(lr=optimizer.param_groups[0][\"lr\"], batch_loss=loss.item(), cls_loss=classification_loss.item(), \n",
    "                            reg_loss=regression_loss.item(), avg_loss=total_loss/(step+1), num_det=num_det)        \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()   \n",
    "\n",
    "    print('{}th epochs loss {} lr {} '.format(epoch, total_loss/(step+1), EPOCH_LEARING_RATE ))\n",
    "    if loss_per_epoch > total_loss/(step+1):\n",
    "        print('best model is saved')\n",
    "        torch.save(model.state_dict(), saved_dir + 'best_model.pt')\n",
    "        loss_per_epoch = total_loss/(step+1)\n",
    "\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0169b5c9-0f1b-4512-b5ee-d1e003c7274d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(background_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418f754c-8039-47c5-aa77-1a44d072adc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# len(background_class)\n",
    "def my_def ( i) :\n",
    "    i = i.cpu()\n",
    "    i = np.array(i)\n",
    "    return i\n",
    "\n",
    "stime = time.time()\n",
    "bg_cls = list(map(my_def, background_class))\n",
    "print('time', time.time() - stime)\n",
    "len(bg_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29376fa6-bb44-4979-a9dc-ef2348085636",
   "metadata": {},
   "outputs": [],
   "source": [
    "fore_cls = list(map(my_def, foreground_class))\n",
    "len(fore_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0968eab1-99da-4f9c-81be-e3643883f771",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(background_class)/len(background_class)\n",
    "# background_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c003b063-6e62-459e-a083-0f16557aed70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (foreground_class)\n",
    "# for_list = []\n",
    "# for i in foreground_class :\n",
    "#     if (i) != torch.tensor(0) :\n",
    "#         for_list.append(i.numpy())\n",
    "# # sum(foreground_class)/len(foreground_class)\n",
    "# sum(for_list)/len(for_list)\n",
    "# # for_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1adccb-5f70-43a9-9bb5-38135832ff89",
   "metadata": {},
   "outputs": [],
   "source": [
    "fore_cls[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0921e8-2612-4632-be1e-55d5cc650408",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b856d26-26ee-47ca-847a-d991f24c6559",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# data = np.random.normal(0, 1, 1000) \n",
    "# data = np.array(background_class)\n",
    "data = np.array(fore_cls)\n",
    "# fixed bin size\n",
    "bins = np.arange(0, 1, 1/20) # fixed bin size\n",
    "\n",
    "plt.xlim([0, 1])\n",
    "\n",
    "plt.hist(data, bins=bins, alpha=0.5)\n",
    "plt.title('Random Gaussian data (fixed bin size)')\n",
    "plt.xlabel('variable X (bin size = 5)')\n",
    "plt.ylabel('count')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f797ba9a-ce0e-4f8b-b5ac-3be31c956812",
   "metadata": {},
   "outputs": [],
   "source": [
    "(bg_cls[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4341a0c2-9150-4a61-8343-02699da80e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = np.random.normal(0, 1, 1000) \n",
    "data = np.array(bg_cls)\n",
    "# data = np.array(for_list)\n",
    "# fixed bin size\n",
    "bins = np.arange(0, 1, 1/50) # fixed bin size\n",
    "\n",
    "plt.xlim([0, 1])\n",
    "\n",
    "stime = time.time()\n",
    "plt.hist(data, bins=bins, alpha=0.5)\n",
    "plt.title('Random Gaussian data (fixed bin size)')\n",
    "plt.xlabel('variable X (bin size = 5)')\n",
    "plt.ylabel('count')\n",
    "plt.show()\n",
    "print('time', time.time() - stime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748b6f95-51e7-4905-9dda-9707c00062dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(2, 2000)\n",
    "a.shape\n",
    "a[1,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc47fb9-9efc-4246-afa2-6bef20058d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pool of square window of size=3, stride=2\n",
    "# m = nn.MaxPool2d((8,8), stride=8)\n",
    "# pool of non-square window\n",
    "m = nn.AvgPool2d((32, 32), stride=(8, 8), padding=12)\n",
    "input = torch.randn(24, 3, 320, 320)\n",
    "output = m(input)\n",
    "output.shape\n",
    "output.mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66baae32-d169-428a-a1db-0539b79987fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Anchors(nn.Module):\n",
    "    def __init__(self, pyramid_levels=None, strides=None, sizes=None, ratios=None, scales=None):\n",
    "        super(Anchors, self).__init__()\n",
    "\n",
    "        if pyramid_levels is None:\n",
    "#             self.pyramid_levels = [3, 4, 5, 6, 7]\n",
    "            self.pyramid_levels = [3, 4]\n",
    "        if strides is None:\n",
    "            self.strides = [2 ** x for x in self.pyramid_levels]\n",
    "        if sizes is None:\n",
    "            self.sizes = [2 ** (x + 2) for x in self.pyramid_levels]\n",
    "        if ratios is None:\n",
    "            self.ratios = np.array([1, 2])\n",
    "#             self.ratios = np.array([0.5, 0.75, 1, 1.25, 1.5])\n",
    "        if scales is None:\n",
    "            self.scales = np.array([2 ** 0, 2 ** 1 ])\n",
    "#             self.scales = np.array([2 ** (-1.0 / 3.0), 2 ** (-3.0 / 3.0), 2 ** 0, 2 ** (1.0 / 3.0) ])\n",
    "#         num anchors per feature map\n",
    "        self.num_anchors = len(self.ratios) * len(self.scales)\n",
    "\n",
    "    def forward(self, image):\n",
    "        \n",
    "        image_shape = image.shape[2:]\n",
    "        image_shape = np.array(image_shape)\n",
    "        image_shapes = [(image_shape + 2 ** x - 1) // (2 ** x) for x in self.pyramid_levels]\n",
    "\n",
    "        # compute anchors over all pyramid levels\n",
    "        all_anchors = np.zeros((0, 4)).astype(np.float32)\n",
    "\n",
    "        for idx, p in enumerate(self.pyramid_levels):\n",
    "            anchors         = generate_anchors(base_size=self.sizes[idx], ratios=self.ratios, scales=self.scales)\n",
    "            shifted_anchors = shift(image_shapes[idx], self.strides[idx], anchors)\n",
    "            all_anchors     = np.append(all_anchors, shifted_anchors, axis=0)\n",
    "\n",
    "        all_anchors = np.expand_dims(all_anchors, axis=0)\n",
    "\n",
    "#         if torch.cuda.is_available():\n",
    "#             return torch.from_numpy(all_anchors.astype(np.float32)).cuda()\n",
    "#         else:\n",
    "#             return torch.from_numpy(all_anchors.astype(np.float32))\n",
    "        return torch.from_numpy(all_anchors.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1c4907-12d0-41b1-ac11-7c0b955f04a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors = Anchors()(torch.randn(24, 3, 20, 20))\n",
    "print(anchors.shape)\n",
    "anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crucial-candle",
   "metadata": {},
   "outputs": [],
   "source": [
    "paps_train.train_paps(dataloader=train_data_loader, \n",
    "                      model=model, \n",
    "                      criterion=criterion,\n",
    "                      saved_dir=saved_dir, \n",
    "                      optimizer=optimizer,\n",
    "                      scheduler=scheduler,\n",
    "                      device = device,\n",
    "                      s_epoch= s_epoch,\n",
    "                      e_epoch= e_epoch,\n",
    "                      last_loss = last_loss)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anonymous-crest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state = {\n",
    "#     'epoch': 0,\n",
    "#     'state_dict': model.state_dict(),\n",
    "#     'optimizer': optimizer.state_dict(),\n",
    "#     'loss' : 0.6\n",
    "# }\n",
    "# torch.save(state, saved_dir + 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "freelance-basics",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_val = PapsDataset('../data/', set_name='val_2class',\n",
    "                            transform=val_transforms)\n",
    "\n",
    "val_data_loader = DataLoader(\n",
    "    dataset_val,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "matched-teens",
   "metadata": {},
   "outputs": [],
   "source": [
    "paps_eval.evaluate_paps(dataset=dataset_val, \n",
    "  dataloader=val_data_loader, \n",
    "  model=model, \n",
    "  saved_dir=saved_dir, \n",
    "  device = device,\n",
    "  threshold=0.1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-reply",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = PapsLoss(device, target_threshold=9, topk=10, filter_option=1)\n",
    "criterion = criterion.to(device)\n",
    "s_epoch= 60\n",
    "e_epoch= 120\n",
    "\n",
    "\n",
    "paps_train.train_paps(dataloader=train_data_loader, \n",
    "                      model=model, \n",
    "                      criterion=criterion,\n",
    "                      saved_dir=saved_dir, \n",
    "                      optimizer=optimizer,\n",
    "                      scheduler=scheduler,\n",
    "                      device = device,\n",
    "                      s_epoch= s_epoch,\n",
    "                      e_epoch= e_epoch,\n",
    "                      last_loss = last_loss)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spectacular-composer",
   "metadata": {},
   "outputs": [],
   "source": [
    "paps_eval.evaluate_paps(dataset=dataset_val, \n",
    "  dataloader=val_data_loader, \n",
    "  model=model, \n",
    "  saved_dir=saved_dir, \n",
    "  device = device,\n",
    "  threshold=0.1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c651491-1fb3-46c0-8883-7b16a96a1f71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_retina",
   "language": "python",
   "name": "torch_retina"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
