{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2acca083-68ba-4081-8c55-f2dede599f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "# import matplotlib.pyplot as plt\n",
    "# from PIL import Image, ImageDraw, ImageEnhance\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# import cv2\n",
    "import re\n",
    "import time\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from retinanet import coco_eval\n",
    "from retinanet import csv_eval\n",
    "from retinanet import model\n",
    "# from retinanet import retina\n",
    "from retinanet.dataloader import *\n",
    "from retinanet.anchors import Anchors\n",
    "from retinanet.losses import *\n",
    "from retinanet.scheduler import *\n",
    "from retinanet.parallel import DataParallelModel, DataParallelCriterion\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "from torch.optim import Adam, lr_scheduler\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce362685-a348-40a6-a97d-1c93bb1d6a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:5\n",
      "Current cuda device  5\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# print ('Available devices ', torch.cuda.device_count())\n",
    "\n",
    "# print ('Current cuda device ', torch.cuda.current_device())\n",
    "# print(torch.cuda.get_device_name(device))\n",
    "\n",
    "# GPU 할당 변경하기\n",
    "GPU_NUM = 5 # 원하는 GPU 번호 입력\n",
    "device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device) # change allocation of current GPU\n",
    "print(device)\n",
    "print ('Current cuda device ', torch.cuda.current_device()) # check\n",
    "device_ids = [5,6]\n",
    "# device_ids = [4,3,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8dc894d-1f8c-423c-8d05-26a1856e232a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # torch.load(PATH_TO_WEIGHTS, map_location=device)\n",
    "# %time\n",
    "# PATH_TO_WEIGHTS = '../coco_resnet_50_map_0_335_state_dict.pt'\n",
    "# retinanet = model.resnet50(num_classes=2, device=device)\n",
    "# retinanet.load_state_dict(torch.load(PATH_TO_WEIGHTS, map_location=device), strict=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb601b18-656b-4a71-a5da-9e548aa7f9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_dict = model.state_dict()\n",
    "# state_dict['classifier.weight'] = torch.randn(10, 10)\n",
    "# model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e50408ec-1900-45a3-a171-5c29ea2bcaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_dict = pretrained_retinanet.state_dict()\n",
    "# state_dict['bn1.bias'] = torch.zeros([64])\n",
    "# state_dict['bn1.bias']\n",
    "# pretrained_retinanet.load_state_dict(state_dict)\n",
    "# pretrained_retinanet.state_dict()['bn1.bias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bc98d78-b624-44c5-8df6-97de32d77f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 4 µs, total: 7 µs\n",
      "Wall time: 16.2 µs\n",
      "num_features_in of ResidualAfterFPN : 256\n",
      "num_features_in of ResidualAfterFPN : 256\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "PATH_TO_WEIGHTS = '../coco_resnet_50_map_0_335_state_dict.pt'\n",
    "pre_retinanet = model.resnet50(num_classes=80, device=device)\n",
    "pre_retinanet.load_state_dict(torch.load(PATH_TO_WEIGHTS, map_location=device), strict=False)\n",
    "pre_retinanet.classificationModel.output = nn.Conv2d(256, 18, kernel_size=3, padding=1)\n",
    "\n",
    "retinanet = model.resnet50(num_classes=2, device=device)\n",
    "retinanet.load_state_dict(pre_retinanet.state_dict(), strict=False)\n",
    "del pre_retinanet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f456889-48a1-44b1-95b6-440846a17b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bn1.weight\n",
      "bn1.bias\n",
      "bn3.weight\n",
      "bn3.bias\n",
      "bn4.weight\n",
      "bn4.bias\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = retinanet.residualafterFPN.state_dict()\n",
    "# state_dict = retinanet.state_dict()\n",
    "for s in state_dict:\n",
    "    if 'bn' in s :\n",
    "        if 'weight' in s :\n",
    "            print(s)\n",
    "            shape = state_dict[s].shape\n",
    "            state_dict[s] = torch.zeros(shape)\n",
    "        elif 'bias' in s :\n",
    "            print(s)\n",
    "            shape = state_dict[s].shape\n",
    "#            state_dict[s] = torch.zeros(shape)\n",
    "            state_dict[s] = torch.ones(shape)            \n",
    "#         print(residual_state_dict[s])\n",
    "retinanet.residualafterFPN.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5dfa0121-9356-45d1-8494-dd8da74d0ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retinanet.to(device)\n",
    "retinanet = torch.nn.DataParallel(retinanet, device_ids = [5,6], output_device=GPU_NUM).to(device)\n",
    "# retinanet = DataParallelModel(retinanet, device_ids = device_ids)\n",
    "#retinanet.to(device)\n",
    "# retinanet.cuda()\n",
    "# retinanet.module.freeze_ex_bn()\n",
    "#retinanet.module.freeze_ex_bn(False)\n",
    "#retinanet.freeze_ex_bn(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48203d83-44cb-4e80-83a3-1f862f8a8e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for n, p in retinanet.named_parameters():\n",
    "#     #print(n)\n",
    "#     if 'bn' not in n :\n",
    "#         if 'fpn' not in n and 'residualafterFPN' not in n and 'regressionModel' not in n and 'classificationModel' not in n :\n",
    "#             #print(param)\n",
    "#             print(n)\n",
    "#             p.requires_grad = False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82ec48a3-b91c-417d-8610-555c69891402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k, p in zip(retinanet.module.state_dict(), retinanet.module.parameters()) :\n",
    "#     if 'bn' not in k :\n",
    "# #         print(k)\n",
    "#         p.requires_grad = False\n",
    "# #         print(p)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbbf8a57-def8-4b32-9904-f9dbf0761f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.89s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# train_info = np.load('../data/train.npy', allow_pickle=True, encoding='latin1').item()\n",
    "# train_info\n",
    "\n",
    "batch_size = 32\n",
    "dataset_train = PapsDataset('../data/', set_name='train_2class',\n",
    "                            transform=train_transforms)\n",
    "\n",
    "train_data_loader = DataLoader(\n",
    "    dataset_train,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=16,\n",
    "    pin_memory=True,\n",
    "    prefetch_factor=1,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79f1eeb3-8cb8-468a-9b27-dddf2b909848",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = FocalLoss(device)\n",
    "criterion = criterion.to(device)\n",
    "retinanet.training = True\n",
    "\n",
    "# https://gaussian37.github.io/dl-pytorch-lr_scheduler/\n",
    "optimizer = optim.Adam(retinanet.parameters(), lr = 1e-8)\n",
    "scheduler = CosineAnnealingWarmUpRestarts(optimizer, T_0=20, T_mult=2, eta_max=0.0008,  T_up=5, gamma=0.5)\n",
    "# CosineAnnealingWarmRestarts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eba7b81d-c5ec-4e5b-b59c-da43b1defd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_dict = retinanet.module.residualafterFPN.state_dict()\n",
    "# for s in state_dict:\n",
    "#     if 'bn' in s :\n",
    "#         if 'weight' in s :\n",
    "#             print(s)\n",
    "#             print(state_dict[s])\n",
    "#         elif 'bias' in s :\n",
    "#             print(s)\n",
    "#             print(state_dict[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48a2b04a-2f68-4941-b52b-307cd47fdbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "retinanet.module.freeze_ex_bn(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff37603d-fe67-45b6-8dd2-312749b50afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3dc41214d2d4431b39b7e819f953243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/465 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****0th epoch, learning rate 2e-05\n",
      "0th epochs loss is 113.3125921336271\n",
      "epoch training time is  227.86394429206848\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f222b129e574a59b9d427bacb8e4384",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/465 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****1th epoch, learning rate 0.000160008\n",
      "1th epochs loss is 0.915842695003849\n",
      "epoch training time is  228.23399019241333\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf54cfbcb62444718538ae62c5b2d196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/465 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****2th epoch, learning rate 0.000320006\n",
      "2th epochs loss is 0.5899777324017832\n",
      "best model is saved\n",
      "epoch training time is  142.6881980895996\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a903396082b24274bd22f7e54732a1a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/465 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****3th epoch, learning rate 0.00048000399999999997\n",
      "3th epochs loss is 0.6253384268384868\n",
      "epoch training time is  199.03216314315796\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23ca2f4ea6684f63a4d64e0b67101624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/465 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****4th epoch, learning rate 0.0006400020000000001\n"
     ]
    }
   ],
   "source": [
    "#for i, data in enumerate(tqdm(train_data_loader)) :\n",
    "EPOCH_NUM = 160\n",
    "loss_per_epoch = 0.6\n",
    "optimizer.param_groups[0][\"lr\"] = 0.00002\n",
    "for epoch in range(EPOCH_NUM) :\n",
    "    if epoch == int(EPOCH_NUM *0.2) :\n",
    "        retinanet.module.freeze_ex_bn(True)\n",
    "    total_loss = 0\n",
    "    tk0 = tqdm(train_data_loader, total=len(train_data_loader), leave=False)\n",
    "    EPOCH_LEARING_RATE = optimizer.param_groups[0][\"lr\"]\n",
    "    start_time = time.time()\n",
    "#     print(\"*****{}th epoch, learning rate {}\".format(epoch, EPOCH_LEARING_RATE))\n",
    "\n",
    "    for step, data in enumerate(tk0) :\n",
    "        if step > len(train_data_loader)/4 and epoch < int(EPOCH_NUM*0.8)  :\n",
    "            break\n",
    "        images, box, label, targets = data\n",
    "        batch_size = len(images)\n",
    "\n",
    "        c, h, w = images[0].shape\n",
    "        images = torch.cat(images).view(-1, c, h, w).to(device)\n",
    "        targets = [ t.to(device) for t in targets]\n",
    "\n",
    "        outputs = retinanet([images, targets])\n",
    "        classification, regression, anchors, annotations = (outputs)\n",
    "        classification_loss, regression_loss = criterion(classification, regression, anchors, annotations)\n",
    "\n",
    "        classification_loss = classification_loss.mean()\n",
    "        regression_loss = regression_loss.mean()\n",
    "        loss = classification_loss + regression_loss \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if step % 5 == 0:\n",
    "            tk0.set_postfix(lr=optimizer.param_groups[0][\"lr\"], batch_loss=loss.item(), cls_loss=classification_loss.item(), \n",
    "                            reg_loss=regression_loss.item(), avg_loss=total_loss/(step+1))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(retinanet.parameters(), 0.02)\n",
    "        optimizer.step()   \n",
    "\n",
    "    print('{}th epochs loss is {}'.format(epoch, total_loss/(step+1)))\n",
    "    if loss_per_epoch > total_loss/(step+1):\n",
    "        print('best model is saved')\n",
    "        torch.save(retinanet.state_dict(), '../trained_models/resnet50_320_ex_bn/best_model.pt')\n",
    "        loss_per_epoch = total_loss/(step+1)\n",
    "        \n",
    "    scheduler.step()\n",
    "#     print('epoch training time is ', time.time() - start_time)\n",
    "\n",
    "torch.save(retinanet.state_dict(), '../trained_models/resnet50_320_ex_bn/model.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48877d10-8ed7-4879-a54d-e87461aa2b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for n, p in retinanet.named_parameters():\n",
    "#     #print(n)\n",
    "#     if 'bn' not in n :\n",
    "#         if 'fpn' not in n and 'residualafterFPN' not in n and 'regressionModel' not in n and 'classificationModel' not in n :\n",
    "#             #print(param)\n",
    "#             print(n)\n",
    "#             print(p[0])\n",
    "#             #p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1f4e53-162c-4f2f-904d-c02cb99521fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for n, p in retinanet.named_parameters():\n",
    "#     #print(n)\n",
    "#     if 'bn' not in n :\n",
    "#         if 'fpn' not in n and 'residualafterFPN' not in n and 'regressionModel' not in n and 'classificationModel' not in n :\n",
    "#             #print(param)\n",
    "#             print(n)\n",
    "#             print(p[0])\n",
    "#             #p.requires_grad = False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ec5d21-6766-4388-baf2-679999e8bcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_dict = retinanet.residualafterFPN.state_dict()\n",
    "# for s in state_dict:\n",
    "#     if 'bn' in s :\n",
    "#         if 'weight' in s :\n",
    "#             print(s)\n",
    "#             print(state_dict[s])\n",
    "#         elif 'bias' in s :\n",
    "#             print(s)\n",
    "#             print(state_dict[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a74eb0d-fd2c-42bf-a9fc-7a794069530a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5fda43-68fa-4cb3-864e-641f4d7aa2bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d27bc5e-e43a-403f-b831-e45df256e77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_val = PapsDataset('../data/', set_name='val_2class',\n",
    "                            transform=val_transforms)\n",
    "\n",
    "val_data_loader = DataLoader(\n",
    "    dataset_val,\n",
    "    batch_size=2,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1770fd54-11b1-4365-80c5-901a623ed559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retinanet.load_state_dict(torch.load('../trained_models/resnet50_320_ex_bn/model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe3f51c-b09b-4f6e-b4a2-c795ac248c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.cocoeval import COCOeval\n",
    "import json\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffe5191-1d0d-4ab3-a529-36245fb144e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "retinanet.eval()\n",
    "start_time = time.time()\n",
    "threshold = 0.1\n",
    "results = []\n",
    "GT_results = []\n",
    "image_ids = []\n",
    "cnt = 0\n",
    "scores_list = []\n",
    "\n",
    "for index, data in enumerate(tqdm(val_data_loader)) :\n",
    "    if cnt > 50 :\n",
    "        break\n",
    "    cnt += 1\n",
    "    with torch.no_grad():        \n",
    "        images, tbox, tlabel, targets = data\n",
    "        batch_size = len(images)\n",
    "#         print(tbox)\n",
    "#         print(len(tbox[0]))\n",
    "\n",
    "        c, h, w = images[0].shape\n",
    "        images = torch.cat(images).view(-1, c, h, w).to(device)\n",
    "\n",
    "        outputs = retinanet(images)\n",
    "        scores, labels, boxes = (outputs)\n",
    "        \n",
    "        scores = scores.cpu()\n",
    "        labels = labels.cpu()\n",
    "        boxes  = boxes.cpu()  \n",
    "        \n",
    "        scores_list.append(scores)\n",
    "\n",
    "        if boxes.shape[0] > 0:\n",
    "            # change to (x, y, w, h) (MS COCO standard)\n",
    "            boxes[:, 2] -= boxes[:, 0]\n",
    "            boxes[:, 3] -= boxes[:, 1]\n",
    "#             print(boxes)\n",
    "\n",
    "            # compute predicted labels and scores\n",
    "            #for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
    "            for box_id in range(boxes.shape[0]):\n",
    "                score = float(scores[box_id])\n",
    "                label = int(labels[box_id])\n",
    "                box = boxes[box_id, :]\n",
    "\n",
    "                # scores are sorted, so we can break\n",
    "                if score < threshold:\n",
    "                    break\n",
    "\n",
    "                # append detection for each positively labeled class\n",
    "                image_result = {\n",
    "                    'image_id'    : dataset_val.image_ids[index],\n",
    "                    'category_id' : dataset_val.label_to_coco_label(label),\n",
    "                    'score'       : float(score),\n",
    "                    'bbox'        : box.tolist(),\n",
    "                }\n",
    "\n",
    "                # append detection to results\n",
    "                results.append(image_result)\n",
    "                \n",
    "        if len(tbox[0]) > 0:    \n",
    "\n",
    "            # compute predicted labels and scores\n",
    "            #for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
    "            for box_id in range(len(tbox[0])):\n",
    "                score = float(0.99)\n",
    "                label = (tlabel[0][box_id])\n",
    "                box = list(tbox[0][box_id])\n",
    "                box[2] -= box[0]\n",
    "                box[3] -= box[1]             \n",
    "\n",
    "                # append detection for each positively labeled class\n",
    "                image_result = {\n",
    "                    'image_id'    : dataset_val.image_ids[index],\n",
    "                    'category_id' : dataset_val.label_to_coco_label(label),\n",
    "                    'score'       : float(score),\n",
    "                    'bbox'        : list(box),\n",
    "                }\n",
    "\n",
    "                # append detection to results\n",
    "                GT_results.append(image_result)                \n",
    "\n",
    "        # append image to list of processed images\n",
    "        image_ids.append(dataset_val.image_ids[index])\n",
    "\n",
    "        # print progress\n",
    "        print('{}/{}'.format(index, len(dataset_val)), end='\\r')    \n",
    "\n",
    "if not len(results):\n",
    "    print('No object detected')\n",
    "print('GT_results', len(GT_results))    \n",
    "print('pred_results', len(results))    \n",
    "\n",
    "# write output\n",
    "json.dump(results, open('../trained_models/resnet50_320_ex_bn/{}_bbox_results.json'.format(dataset_val.set_name), 'w'), indent=4)\n",
    "# write GT\n",
    "json.dump(GT_results, open('../trained_models/resnet50_320_ex_bn/{}_GTbbox_results.json'.format(dataset_val.set_name), 'w'), indent=4)     \n",
    "\n",
    "print('validation time :', time.time() - start_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b57d72b-8011-4f14-b5f9-7fc1e719cc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load results in COCO evaluation tool\n",
    "coco_true = dataset_val.coco\n",
    "coco_pred = coco_true.loadRes('../trained_models/resnet50_320_ex_bn/{}_bbox_results.json'.format(dataset_val.set_name))\n",
    "coco_gt = coco_true.loadRes('../trained_models/resnet50_320_ex_bn/{}_GTbbox_results.json'.format(dataset_val.set_name))\n",
    "\n",
    "# run COCO evaluation\n",
    "# coco_eval = COCOeval(coco_true, coco_pred, 'bbox')\n",
    "coco_eval = COCOeval(coco_gt, coco_pred, 'bbox')\n",
    "coco_eval.params.imgIds = image_ids\n",
    "# coco_eval.params.catIds = [0]\n",
    "coco_eval.evaluate()\n",
    "coco_eval.accumulate()\n",
    "coco_eval.summarize()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bffadf4-df54-455f-b736-8cfec749e0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_eval.params.catIds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e060c0f6-d254-40a5-9fd3-ccd06080eead",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_eval = COCOeval(coco_gt, coco_pred, 'bbox')\n",
    "coco_eval.params.imgIds = image_ids\n",
    "coco_eval.params.catIds = [0]\n",
    "coco_eval.evaluate()\n",
    "coco_eval.accumulate()\n",
    "coco_eval.summarize()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a3736d-4c3e-4de9-91ad-6edc21dd2ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_eval = COCOeval(coco_gt, coco_pred, 'bbox')\n",
    "coco_eval.params.imgIds = image_ids\n",
    "coco_eval.params.catIds = [1]\n",
    "coco_eval.evaluate()\n",
    "coco_eval.accumulate()\n",
    "coco_eval.summarize()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342cba74-3d6a-414b-b80e-e6408af073a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_retina",
   "language": "python",
   "name": "torch_retina"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
