{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2acca083-68ba-4081-8c55-f2dede599f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw, ImageEnhance\n",
    "import albumentations as A\n",
    "import albumentations.pytorch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import cv2\n",
    "import re\n",
    "import time\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from retinanet import coco_eval\n",
    "from retinanet import csv_eval\n",
    "from retinanet import model\n",
    "# from retinanet import retina\n",
    "from retinanet.dataloader import *\n",
    "from retinanet.anchors import Anchors\n",
    "from retinanet.losses import *\n",
    "from retinanet.scheduler import *\n",
    "from retinanet.parallel import DataParallelModel, DataParallelCriterion\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "from torch.optim import Adam, lr_scheduler\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce362685-a348-40a6-a97d-1c93bb1d6a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Current cuda device  0\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# print ('Available devices ', torch.cuda.device_count())\n",
    "\n",
    "# print ('Current cuda device ', torch.cuda.current_device())\n",
    "# print(torch.cuda.get_device_name(device))\n",
    "\n",
    "# GPU 할당 변경하기\n",
    "GPU_NUM = 0 # 원하는 GPU 번호 입력\n",
    "device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device) # change allocation of current GPU\n",
    "print(device)\n",
    "print ('Current cuda device ', torch.cuda.current_device()) # check\n",
    "device_ids = [0,1,2,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bc98d78-b624-44c5-8df6-97de32d77f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 7 µs, total: 11 µs\n",
      "Wall time: 21.9 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "PATH_TO_WEIGHTS = '../coco_resnet_50_map_0_335_state_dict.pt'\n",
    "pretrained_retinanet = model.resnet50(num_classes=80, device=device)\n",
    "pretrained_retinanet.load_state_dict(torch.load(PATH_TO_WEIGHTS))\n",
    "\n",
    "\n",
    "retinanet = model.resnet50(num_classes=5, device=device)\n",
    "for param, state in zip(pretrained_retinanet.parameters(), pretrained_retinanet.state_dict()) :\n",
    "    #print(state)\n",
    "    if 'classificationModel' not in state :\n",
    "        retinanet.state_dict()[state] = param\n",
    "    else :\n",
    "        print(state)\n",
    "    \n",
    "for param, state in zip(pretrained_retinanet.fpn.parameters(), pretrained_retinanet.fpn.state_dict()) :\n",
    "    #print(state)\n",
    "    retinanet.fpn.state_dict()[state] = param\n",
    "\n",
    "for param, state in zip(pretrained_retinanet.regressionModel.parameters(), pretrained_retinanet.regressionModel.state_dict()) :\n",
    "    #print(state)\n",
    "    retinanet.regressionModel.state_dict()[state] = param  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dfa0121-9356-45d1-8494-dd8da74d0ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# retinanet.to(device)\n",
    "retinanet = torch.nn.DataParallel(retinanet, device_ids = [0,1,2,4], output_device=0).to(device)\n",
    "# retinanet = DataParallelModel(retinanet, device_ids = device_ids)\n",
    "retinanet.to(device)\n",
    "# retinanet.cuda()\n",
    "retinanet.module.freeze_bn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e951521b-5314-4f17-ae29-32619ec0fc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbbf8a57-def8-4b32-9904-f9dbf0761f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.82s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# train_info = np.load('../data/train.npy', allow_pickle=True, encoding='latin1').item()\n",
    "# train_info\n",
    "\n",
    "batch_size = 32\n",
    "dataset_train = PapsDataset('../data/', set_name='train',\n",
    "                            transform=train_transforms)\n",
    "\n",
    "train_data_loader = DataLoader(\n",
    "    dataset_train,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=16,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79f1eeb3-8cb8-468a-9b27-dddf2b909848",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = FocalLoss(device)\n",
    "criterion = criterion.to(device)\n",
    "retinanet.training = True\n",
    "\n",
    "# https://gaussian37.github.io/dl-pytorch-lr_scheduler/\n",
    "optimizer = optim.Adam(retinanet.parameters(), lr = 1e-7)\n",
    "scheduler = CosineAnnealingWarmUpRestarts(optimizer, T_0=20, T_mult=1, eta_max=0.0001,  T_up=5, gamma=0.5)\n",
    "# CosineAnnealingWarmRestarts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ba5c62c-6c0d-4fc7-b431-ecad98e67182",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  for data in tqdm(train_data_loader)  :\n",
    "#         pass\n",
    "# #         print(data)\n",
    "# #         sdfsf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff37603d-fe67-45b6-8dd2-312749b50afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #for i, data in enumerate(tqdm(train_data_loader)) :\n",
    "# EPOCH_NUM = 60\n",
    "# loss_per_epoch = 0.5\n",
    "# epoch_time_list = []\n",
    "# for epoch in range(EPOCH_NUM) :\n",
    "#     epoch_loss = []\n",
    "#     total_loss = 0\n",
    "#     tk0 = tqdm(train_data_loader, total=len(train_data_loader), leave=False)\n",
    "#     EPOCH_LEARING_RATE = optimizer.param_groups[0][\"lr\"]\n",
    "#     start_time = time.time()\n",
    "#     print(\"*****{}th epoch, learning rate {}\".format(epoch, EPOCH_LEARING_RATE))\n",
    "\n",
    "#     for step, data in enumerate(tk0) :\n",
    "#         images, box, label, targets = data\n",
    "#         batch_size = len(images)\n",
    "\n",
    "#     #     images = list(image.to(device) for image in images)\n",
    "#         c, h, w = images[0].shape\n",
    "#         images = torch.cat(images).view(-1, c, h, w).to(device)\n",
    "# #         print(images.shape)\n",
    "# #         targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "#         targets = [ t.to(device) for t in targets]\n",
    "\n",
    "# #         classification_loss, regression_loss = retinanet([images, targets])\n",
    "#         outputs = retinanet([images, targets])\n",
    "#         classification, regression, anchors, annotations = (outputs)\n",
    "#         classification_loss, regression_loss = criterion(classification, regression, anchors, annotations)\n",
    "\n",
    "# #         output = retinanet(images)\n",
    "# #         features, regression, classification = output\n",
    "# #         classification_loss, regression_loss = criterion(classification, regression, modified_anchors, targets)    \n",
    "#         classification_loss = classification_loss.mean()\n",
    "#         regression_loss = regression_loss.mean()\n",
    "#         loss = classification_loss + regression_loss \n",
    "#         total_loss += loss.item()\n",
    "        \n",
    "#         epoch_loss.append((loss.item()))\n",
    "#         tk0.set_postfix(lr=optimizer.param_groups[0][\"lr\"], batch_loss=loss.item(), cls_loss=classification_loss.item(), \n",
    "#                         reg_loss=regression_loss.item(), avg_loss=total_loss/(step+1))\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         torch.nn.utils.clip_grad_norm_(retinanet.parameters(), 0.1)\n",
    "#         optimizer.step()   \n",
    "\n",
    "#     print('{}th epochs loss is {}'.format(epoch, np.mean(epoch_loss)))\n",
    "#     if loss_per_epoch > np.mean(epoch_loss):\n",
    "#         print('best model is saved')\n",
    "#         torch.save(retinanet.state_dict(), 'best_model.pt')\n",
    "#         loss_per_epoch = np.mean(epoch_loss)\n",
    "# #     scheduler.step(np.mean(epoch_loss))\n",
    "#     scheduler.step()\n",
    "#     epoch_time_list.append(time.time() - start_time)\n",
    "\n",
    "# torch.save(retinanet.state_dict(), '../trained_models/model.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b5fda43-68fa-4cb3-864e-641f4d7aa2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d27bc5e-e43a-403f-b831-e45df256e77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.43s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "dataset_val = PapsDataset('../data/', set_name='val',\n",
    "                            transform=val_transforms)\n",
    "\n",
    "val_data_loader = DataLoader(\n",
    "    dataset_val,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1770fd54-11b1-4365-80c5-901a623ed559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retinanet.load_state_dict(torch.load('../trained_models/model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebe3f51c-b09b-4f6e-b4a2-c795ac248c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.cocoeval import COCOeval\n",
    "import json\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5ffe5191-1d0d-4ab3-a529-36245fb144e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe81110a4885492298fb083354110b4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3739 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT_results 1465\n",
      "pred_results 1124\n",
      "validation time : 77.84319710731506\n"
     ]
    }
   ],
   "source": [
    "retinanet.eval()\n",
    "start_time = time.time()\n",
    "threshold = 0.1\n",
    "results = []\n",
    "GT_results = []\n",
    "image_ids = []\n",
    "cnt = 0\n",
    "scores_list = []\n",
    "\n",
    "for index, data in enumerate(tqdm(val_data_loader)) :\n",
    "    if cnt > 300 :\n",
    "        break\n",
    "    cnt += 1\n",
    "    with torch.no_grad():        \n",
    "        images, tbox, tlabel, targets = data\n",
    "        batch_size = len(images)\n",
    "#         print(tbox)\n",
    "#         print(len(tbox[0]))\n",
    "\n",
    "        c, h, w = images[0].shape\n",
    "        images = torch.cat(images).view(-1, c, h, w).to(device)\n",
    "\n",
    "        outputs = retinanet(images)\n",
    "        scores, labels, boxes = (outputs)\n",
    "        \n",
    "        scores = scores.cpu()\n",
    "        labels = labels.cpu()\n",
    "        boxes  = boxes.cpu()  \n",
    "        \n",
    "        scores_list.append(scores)\n",
    "\n",
    "        if boxes.shape[0] > 0:\n",
    "            # change to (x, y, w, h) (MS COCO standard)\n",
    "            boxes[:, 2] -= boxes[:, 0]\n",
    "            boxes[:, 3] -= boxes[:, 1]\n",
    "#             print(boxes)\n",
    "\n",
    "            # compute predicted labels and scores\n",
    "            #for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
    "            for box_id in range(boxes.shape[0]):\n",
    "                score = float(scores[box_id])\n",
    "                label = int(labels[box_id])\n",
    "                box = boxes[box_id, :]\n",
    "\n",
    "                # scores are sorted, so we can break\n",
    "                if score < threshold:\n",
    "                    break\n",
    "\n",
    "                # append detection for each positively labeled class\n",
    "                image_result = {\n",
    "                    'image_id'    : dataset_val.image_ids[index],\n",
    "                    'category_id' : dataset_val.label_to_coco_label(label),\n",
    "                    'score'       : float(score),\n",
    "                    'bbox'        : box.tolist(),\n",
    "                }\n",
    "\n",
    "                # append detection to results\n",
    "                results.append(image_result)\n",
    "                \n",
    "        if len(tbox[0]) > 0:    \n",
    "\n",
    "            # compute predicted labels and scores\n",
    "            #for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
    "            for box_id in range(len(tbox[0])):\n",
    "                score = float(0.99)\n",
    "                label = (tlabel[0][box_id])\n",
    "                box = list(tbox[0][box_id])\n",
    "                box[2] -= box[0]\n",
    "                box[3] -= box[1]             \n",
    "\n",
    "                # append detection for each positively labeled class\n",
    "                image_result = {\n",
    "                    'image_id'    : dataset_val.image_ids[index],\n",
    "                    'category_id' : dataset_val.label_to_coco_label(label),\n",
    "                    'score'       : float(score),\n",
    "                    'bbox'        : list(box),\n",
    "                }\n",
    "\n",
    "                # append detection to results\n",
    "                GT_results.append(image_result)                \n",
    "\n",
    "        # append image to list of processed images\n",
    "        image_ids.append(dataset_val.image_ids[index])\n",
    "\n",
    "        # print progress\n",
    "        print('{}/{}'.format(index, len(dataset_val)), end='\\r')    \n",
    "\n",
    "if not len(results):\n",
    "    print('No object detected')\n",
    "print('GT_results', len(GT_results))    \n",
    "print('pred_results', len(results))    \n",
    "\n",
    "# write output\n",
    "json.dump(results, open('{}_bbox_results.json'.format(dataset_val.set_name), 'w'), indent=4)\n",
    "# write GT\n",
    "json.dump(GT_results, open('{}_GTbbox_results.json'.format(dataset_val.set_name), 'w'), indent=4)     \n",
    "\n",
    "print('validation time :', time.time() - start_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6b57d72b-8011-4f14-b5f9-7fc1e719cc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.10s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.366\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.564\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.443\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.366\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.290\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.565\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.582\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.582\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"
     ]
    }
   ],
   "source": [
    "# load results in COCO evaluation tool\n",
    "coco_true = dataset_val.coco\n",
    "coco_pred = coco_true.loadRes('{}_bbox_results.json'.format(dataset_val.set_name))\n",
    "coco_gt = coco_true.loadRes('{}_GTbbox_results.json'.format(dataset_val.set_name))\n",
    "\n",
    "# run COCO evaluation\n",
    "# coco_eval = COCOeval(coco_true, coco_pred, 'bbox')\n",
    "coco_eval = COCOeval(coco_gt, coco_pred, 'bbox')\n",
    "coco_eval.params.imgIds = image_ids\n",
    "# coco_eval.params.catIds = [0]\n",
    "coco_eval.evaluate()\n",
    "coco_eval.accumulate()\n",
    "coco_eval.summarize()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7bffadf4-df54-455f-b736-8cfec749e0b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco_eval.params.catIds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e060c0f6-d254-40a5-9fd3-ccd06080eead",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_retina",
   "language": "python",
   "name": "torch_retina"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
