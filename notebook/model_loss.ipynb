{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27daec0d-e87a-499e-bb51-5301a62e91c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw, ImageEnhance\n",
    "import albumentations as A\n",
    "import albumentations.pytorch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import cv2\n",
    "import re\n",
    "import time\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from retinanet import coco_eval\n",
    "from retinanet import csv_eval\n",
    "from retinanet import model\n",
    "# from retinanet import retina\n",
    "from retinanet.dataloader import *\n",
    "from retinanet.anchors import Anchors\n",
    "from retinanet.losses import *\n",
    "from retinanet.scheduler import *\n",
    "from retinanet.parallel import DataParallelModel, DataParallelCriterion\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "from torch.optim import Adam, lr_scheduler\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63695a10-73d3-4270-8f65-9b6f0ddf3465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:4\n",
      "Current cuda device  4\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# print ('Available devices ', torch.cuda.device_count())\n",
    "\n",
    "# print ('Current cuda device ', torch.cuda.current_device())\n",
    "# print(torch.cuda.get_device_name(device))\n",
    "\n",
    "# GPU 할당 변경하기\n",
    "GPU_NUM = 4 # 원하는 GPU 번호 입력\n",
    "device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device) # change allocation of current GPU\n",
    "print(device)\n",
    "print ('Current cuda device ', torch.cuda.current_device()) # check\n",
    "device_ids = [4,0,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccabc613-1c05-4a57-a88f-66ea2f6ba7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0, 2, 3, 4'\n",
    "# print ('Current cuda device ', torch.cuda.current_device()) # check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83074258-ddf4-44e8-ad4c-b81810054faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda')\n",
    "# device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4742de6b-525f-4903-b972-7ab396a38435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %time\n",
    "# PATH_TO_WEIGHTS = '../coco_resnet_50_map_0_335_state_dict.pt'\n",
    "# retinanet = model.resnet50(num_classes=5,)\n",
    "# # retinanet.load_state_dict(torch.load(PATH_TO_WEIGHTS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93fffb6d-2dd6-4a3e-8a71-0f8d9b2ebfc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13 µs, sys: 0 ns, total: 13 µs\n",
      "Wall time: 29.3 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "PATH_TO_WEIGHTS = '../coco_resnet_50_map_0_335_state_dict.pt'\n",
    "pretrained_retinanet = model.resnet50(num_classes=80, device=device)\n",
    "pretrained_retinanet.load_state_dict(torch.load(PATH_TO_WEIGHTS))\n",
    "\n",
    "\n",
    "retinanet = model.resnet50(num_classes=5, device=device)\n",
    "for param, state in zip(pretrained_retinanet.parameters(), pretrained_retinanet.state_dict()) :\n",
    "    #print(state)\n",
    "    if 'classificationModel' not in state :\n",
    "        retinanet.state_dict()[state] = param\n",
    "    else :\n",
    "        print(state)\n",
    "    \n",
    "for param, state in zip(pretrained_retinanet.fpn.parameters(), pretrained_retinanet.fpn.state_dict()) :\n",
    "    #print(state)\n",
    "    retinanet.fpn.state_dict()[state] = param\n",
    "\n",
    "for param, state in zip(pretrained_retinanet.regressionModel.parameters(), pretrained_retinanet.regressionModel.state_dict()) :\n",
    "    #print(state)\n",
    "    retinanet.regressionModel.state_dict()[state] = param  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3098efd-f40c-4507-97bf-8f588c01fd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pypi.org/project/torch-encoding/\n",
    "# torch-encoding should be installed\n",
    "# pip install torch-encoding\n",
    "# import torch.encoding as encoding\n",
    "# retinanet = encoding.nn.DataParallelModel(retinanet, device_ids = [4,0,2,3]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ac06499-05a2-42ae-99d4-4a89e6d1eb5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (fpn): PyramidFeatures(\n",
       "      (P5_1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (P5_upsampled): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (P5_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (P4_1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (P4_upsampled): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (P4_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (P3_1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (P3_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (P6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (P7_1): ReLU()\n",
       "      (P7_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "    (regressionModel): RegressionModel(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act1): ReLU()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act2): ReLU()\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act3): ReLU()\n",
       "      (conv4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act4): ReLU()\n",
       "      (output): Conv2d(256, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (classificationModel): ClassificationModel(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act1): ReLU()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act2): ReLU()\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act3): ReLU()\n",
       "      (conv4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act4): ReLU()\n",
       "      (output): Conv2d(256, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (output_act): Sigmoid()\n",
       "    )\n",
       "    (anchors): Anchors()\n",
       "    (regressBoxes): BBoxTransform()\n",
       "    (clipBoxes): ClipBoxes()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# retinanet.to(device)\n",
    "retinanet = torch.nn.DataParallel(retinanet, device_ids = [4,0,2,3], output_device=4).to(device)\n",
    "# retinanet = DataParallelModel(retinanet, device_ids = device_ids)\n",
    "retinanet.to(device)\n",
    "# retinanet.cuda()\n",
    "\n",
    "# retinanet.module.freeze_bn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d31fe47-5830-48b5-9dec-1dc60a9b3705",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_info = np.load('../data/train.npy', allow_pickle=True, encoding='latin1').item()\n",
    "# train_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc7eb86b-11d6-4388-9baa-d94f2030ac15",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_ds = PapsDataset(train_info, transforms)\n",
    "\n",
    "train_data_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c68a2949-545d-42e8-bdf9-e24b2f74971b",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = FocalLoss(device)\n",
    "# criterion = DataParallelCriterion(criterion, device_ids = device_ids) \n",
    "criterion = criterion.to(device)\n",
    "# optimizer = optim.Adam(retinanet.parameters(), lr=1e-4)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, verbose=True)\n",
    "# retinanet.train()\n",
    "retinanet.training = True\n",
    "# retinanet.module.freeze_bn()    \n",
    "# retinanet.freeze_bn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d82f31c2-6953-44c1-82cf-4c8ccdb88b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://gaussian37.github.io/dl-pytorch-lr_scheduler/\n",
    "optimizer = optim.Adam(retinanet.parameters(), lr = 1e-7)\n",
    "scheduler = CosineAnnealingWarmUpRestarts(optimizer, T_0=20, T_mult=1, eta_max=0.0005,  T_up=5, gamma=0.5)\n",
    "# CosineAnnealingWarmRestarts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29ddf481-9f02-4fa3-a567-d053233630ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'T_0': 20,\n",
       " 'T_mult': 1,\n",
       " 'base_eta_max': 0.0005,\n",
       " 'eta_max': 0.0005,\n",
       " 'T_up': 5,\n",
       " 'T_i': 20,\n",
       " 'gamma': 0.5,\n",
       " 'cycle': 0,\n",
       " 'T_cur': 0,\n",
       " 'base_lrs': [1e-07],\n",
       " 'last_epoch': 0,\n",
       " '_step_count': 0,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scheduler.state_dict()\n",
    "# # scheduler._last_lr\n",
    "# optimizer.param_groups[0][\"lr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5f2f80-02f2-4b90-8f85-6bb5c044ed3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48d45a0c0a4243708333cc2562abe4b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/468 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****0th epoch, learning rate 1e-07\n"
     ]
    }
   ],
   "source": [
    "#for i, data in enumerate(tqdm(train_data_loader)) :\n",
    "EPOCH_NUM = 60\n",
    "loss_per_epoch = 2\n",
    "for epoch in range(EPOCH_NUM) :\n",
    "    epoch_loss = []\n",
    "    total_loss = 0\n",
    "    tk0 = tqdm(train_data_loader, total=len(train_data_loader), leave=False)\n",
    "    EPOCH_LEARING_RATE = optimizer.param_groups[0][\"lr\"]\n",
    "    print(\"*****{}th epoch, learning rate {}\".format(epoch, EPOCH_LEARING_RATE))\n",
    "    \n",
    "    for step, data in enumerate(tk0) :\n",
    "        images, _, paths, targets = data\n",
    "#         print(targets)\n",
    "        batch_size = len(images)\n",
    "\n",
    "    #     images = list(image.to(device) for image in images)\n",
    "        c, h, w = images[0].shape\n",
    "        images = torch.cat(images).view(-1, c, h, w).to(device)\n",
    "#         targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        targets = [ t.to(device) for t in targets]\n",
    "\n",
    "#         classification_loss, regression_loss = retinanet([images, targets])\n",
    "        outputs = retinanet([images, targets])\n",
    "        classification, regression, anchors, annotations = (outputs)\n",
    "        classification_loss, regression_loss = criterion(classification, regression, anchors, annotations)\n",
    "\n",
    "#         output = retinanet(images)\n",
    "#         features, regression, classification = output\n",
    "#         classification_loss, regression_loss = criterion(classification, regression, modified_anchors, targets)    \n",
    "        classification_loss = classification_loss.mean()\n",
    "        regression_loss = regression_loss.mean()\n",
    "        loss = classification_loss + regression_loss \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        epoch_loss.append((loss.item()))\n",
    "        tk0.set_postfix(lr=optimizer.param_groups[0][\"lr\"], batch_loss=loss.item(), cls_loss=classification_loss.item(), \n",
    "                        reg_loss=regression_loss.item(), avg_loss=total_loss/(step+1))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(retinanet.parameters(), 0.1)\n",
    "        optimizer.step()   \n",
    "\n",
    "    print('{}th epochs loss is {}'.format(epoch, np.mean(epoch_loss)))\n",
    "    if loss_per_epoch > np.mean(epoch_loss):\n",
    "        print('best model is saved')\n",
    "        torch.save(retinanet.state_dict(), 'best_model.pt')\n",
    "        loss_per_epoch = np.mean(epoch_loss)\n",
    "#     scheduler.step(np.mean(epoch_loss))\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fab06e-4e91-43a8-bede-1a0b0ee8bb28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf939dc0-b511-4d07-821f-747b99120667",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(retinanet.state_dict(), '../trained_models/model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d9510b-ff17-4454-8fd6-d4dec39ac8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "retinanet.load_state_dict(torch.load('../trained_models/model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c356a3f3-f5c0-4e10-b407-eeb26beeeaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retinanet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b36467-11dc-49ea-839c-ca94d6f088a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_info = np.load('../data/test.npy', allow_pickle=True, encoding='latin1').item()\n",
    "# train_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e43969b-080e-4cfd-ae4d-f1a0c73163d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = PapsDataset(test_info,val_transforms)\n",
    "\n",
    "test_data_loader = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4abc8f4-9e92-4bf8-8c93-583033eec9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "retinanet.eval()\n",
    "# retinanet.training = True\n",
    "tk1 = tqdm(test_data_loader, total=len(test_data_loader),leave=False)\n",
    "for step, data in enumerate(tk1) :\n",
    "    with torch.no_grad():\n",
    "        images, _, paths, targets = data\n",
    "        batch_size = len(images)\n",
    "        c, h, w = images[0].shape\n",
    "        images = torch.cat(images).view(-1, c, h, w).to(device)\n",
    "        print(images.shape)\n",
    "        targets = [ t.to(device) for t in targets]   \n",
    "        \n",
    "        scores, labels, boxes = retinanet(images)\n",
    "        print(scores)\n",
    "        print(labels)\n",
    "        print(boxes)\n",
    "        adfsfd\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cc3c04-8d71-402f-b413-134cf4c50ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "retinanet.eval()\n",
    "retinanet.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0abac4d-25f2-49b8-9dee-e0727bce277f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a90d644-c312-4af0-8cf9-2cb6ae775ab9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_retina",
   "language": "python",
   "name": "torch_retina"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
