{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "joint-yacht",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "# import os\n",
    "# import matplotlib.pyplot as plt\n",
    "# from PIL import Image, ImageDraw, ImageEnhance\n",
    "# from tqdm.notebook import tqdm\n",
    "from tqdm import tqdm\n",
    "\n",
    "# import cv2\n",
    "# import re\n",
    "# import time\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from retinanet import coco_eval\n",
    "from retinanet import csv_eval\n",
    "from retinanet import model\n",
    "# from retinanet import retina\n",
    "from retinanet.dataloader import *\n",
    "from retinanet.anchors import Anchors\n",
    "from retinanet.losses import *\n",
    "from retinanet.scheduler import *\n",
    "from retinanet.parallel import DataParallelModel, DataParallelCriterion\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "from torch.optim import Adam, lr_scheduler\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "quick-aberdeen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_features_in of ResidualAfterFPN : 256\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "# device = torch.device('cuda')\n",
    "retinanet = model.resnet101(num_classes=2, device=device)\n",
    "# retinanet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "infinite-alexander",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 320, 320])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor = Anchors()\n",
    "img = torch.randn([4,3,320,320])\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "recorded-delivery",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors = anchor(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sunset-panama",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-12., -12.,  20.,  20.],\n",
       "         [ -4., -12.,  28.,  20.],\n",
       "         [  4., -12.,  36.,  20.],\n",
       "         ...,\n",
       "         [284., 300., 316., 332.],\n",
       "         [292., 300., 324., 332.],\n",
       "         [300., 300., 332., 332.]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchors[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "lasting-cabin",
   "metadata": {},
   "outputs": [],
   "source": [
    "myan = anchors[:,500:510]\n",
    "myan = torch.tensor([[[148.,  84., 180., 116.],\n",
    "         [156.,  84., 188., 116.],\n",
    "         [164.,  84., 196., 116.],\n",
    "         [172.,  84., 204., 116.],\n",
    "         [180.,  84., 212., 116.],\n",
    "         [188.,  84., 220., 116.],\n",
    "         [196.,  84., 228., 116.],\n",
    "         [204.,  84., 236., 116.],\n",
    "         [212.,  84., 244., 116.],\n",
    "         [260.,  84., 292., 116.]]])\n",
    "a = myan[0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "compressed-playing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1350e+02, 1.3725e+02, 1.3700e+02, 1.5975e+02, 0.0000e+00],\n",
       "        [1.4000e+02, 8.2000e+01, 1.8200e+02, 1.2000e+02, 0.0000e+00],\n",
       "        [1.4250e+02, 2.5000e-01, 1.7075e+02, 2.3500e+01, 0.0000e+00],\n",
       "        [2.0000e+02, 7.2000e+01, 2.4200e+02, 1.1000e+02, 1.0000e+00],\n",
       "        [2.8075e+02, 2.7600e+02, 3.1225e+02, 3.0150e+02, 0.0000e+00]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation = torch.tensor([[1.1350e+02, 1.3725e+02, 1.3700e+02, 1.5975e+02, 0.0000e+00],\n",
    "        [140, 82, 182, 120, 0.0000e+00],\n",
    "        [1.4250e+02, 2.5000e-01, 1.7075e+02, 2.3500e+01, 0.0000e+00],\n",
    "        [200, 72, 242, 110, 1.0000e+00],\n",
    "        [2.8075e+02, 2.7600e+02, 3.1225e+02, 3.0150e+02, 0.0000e+00]])\n",
    "annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "greenhouse-invalid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 528.7500, 1596.0000,  656.8125, 1596.0000,  803.2500])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = annotation\n",
    "area = (b[:, 2] - b[:, 0]) * (b[:, 3] - b[:, 1])\n",
    "area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "headed-print",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[180.],\n",
       "        [188.],\n",
       "        [196.],\n",
       "        [204.],\n",
       "        [212.],\n",
       "        [220.],\n",
       "        [228.],\n",
       "        [236.],\n",
       "        [244.],\n",
       "        [292.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unsqueeze(a[:, 2], dim=1)\n",
    "# b[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "administrative-latest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([137.0000, 182.0000, 170.7500, 242.0000, 312.2500])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sustained-focus",
   "metadata": {},
   "outputs": [],
   "source": [
    "iw = torch.min(torch.unsqueeze(a[:, 2], dim=1), b[:, 2]) - torch.max(torch.unsqueeze(a[:, 0], 1), b[:, 0])\n",
    "ih = torch.min(torch.unsqueeze(a[:, 3], dim=1), b[:, 3]) - torch.max(torch.unsqueeze(a[:, 1], 1), b[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "unavailable-offset",
   "metadata": {},
   "outputs": [],
   "source": [
    "iw = torch.min(torch.unsqueeze(a[:, 2], dim=1), b[:, 2]) - torch.max(torch.unsqueeze(a[:, 0], 1), b[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "remarkable-platinum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.clamp(iw * ih, min=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "tribal-thanksgiving",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0., 1024.,    0.,    0.,    0.],\n",
       "        [   0.,  832.,    0.,    0.,    0.],\n",
       "        [   0.,  576.,    0.,    0.,    0.],\n",
       "        [   0.,  320.,    0.,  104.,    0.],\n",
       "        [   0.,   64.,    0.,  312.,    0.],\n",
       "        [   0.,    0.,    0.,  520.,    0.],\n",
       "        [   0.,    0.,    0.,  728.,    0.],\n",
       "        [   0.,    0.,    0.,  832.,    0.],\n",
       "        [   0.,    0.,    0.,  780.,    0.],\n",
       "        [   0.,    0.,    0.,    0.,    0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iw = torch.clamp(iw, min=0)\n",
    "ih = torch.clamp(ih, min=0)\n",
    "iw * ih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "matched-rough",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.6416, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.5213, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.3609, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.2005, 0.0000, 0.0652, 0.0000],\n",
       "        [0.0000, 0.0401, 0.0000, 0.1955, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.3258, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.4561, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.5213, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.4887, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.clamp(iw * ih / area, min=0, max=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "pacific-separation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1552.7500, 1596.0000, 1680.8125, 2620.0000, 1827.2500],\n",
       "        [1552.7500, 1788.0000, 1680.8125, 2620.0000, 1827.2500],\n",
       "        [1552.7500, 2044.0000, 1680.8125, 2620.0000, 1827.2500],\n",
       "        [1552.7500, 2300.0000, 1680.8125, 2516.0000, 1827.2500],\n",
       "        [1552.7500, 2556.0000, 1680.8125, 2308.0000, 1827.2500],\n",
       "        [1552.7500, 2620.0000, 1680.8125, 2100.0000, 1827.2500],\n",
       "        [1552.7500, 2620.0000, 1680.8125, 1892.0000, 1827.2500],\n",
       "        [1552.7500, 2620.0000, 1680.8125, 1788.0000, 1827.2500],\n",
       "        [1552.7500, 2620.0000, 1680.8125, 1840.0000, 1827.2500],\n",
       "        [1552.7500, 2620.0000, 1680.8125, 2620.0000, 1827.2500]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unsqueeze((a[:, 2] - a[:, 0]) * (a[:, 3] - a[:, 1]), dim=1) + area - iw * ih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "binding-principal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1552.7500, 1596.0000, 1680.8125, 2620.0000, 1827.2500],\n",
       "        [1552.7500, 1788.0000, 1680.8125, 2620.0000, 1827.2500],\n",
       "        [1552.7500, 2044.0000, 1680.8125, 2620.0000, 1827.2500],\n",
       "        [1552.7500, 2300.0000, 1680.8125, 2516.0000, 1827.2500],\n",
       "        [1552.7500, 2556.0000, 1680.8125, 2308.0000, 1827.2500],\n",
       "        [1552.7500, 2620.0000, 1680.8125, 2100.0000, 1827.2500],\n",
       "        [1552.7500, 2620.0000, 1680.8125, 1892.0000, 1827.2500],\n",
       "        [1552.7500, 2620.0000, 1680.8125, 1788.0000, 1827.2500],\n",
       "        [1552.7500, 2620.0000, 1680.8125, 1840.0000, 1827.2500],\n",
       "        [1552.7500, 2620.0000, 1680.8125, 2620.0000, 1827.2500]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unsqueeze((a[:, 2] - a[:, 0]) * (a[:, 3] - a[:, 1]), dim=1) + area - iw * ih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "surprised-superior",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     area = (b[:, 2] - b[:, 0]) * (b[:, 3] - b[:, 1])\n",
    "\n",
    "# #     print(torch.min(torch.unsqueeze(a[:, 2], dim=1), b[:, 2]))\n",
    "# #     print(torch.max(torch.unsqueeze(a[:, 0], 1), b[:, 0]))\n",
    "#     iw = torch.min(torch.unsqueeze(a[:, 2], dim=1), b[:, 2]) - torch.max(torch.unsqueeze(a[:, 0], 1), b[:, 0])\n",
    "#     ih = torch.min(torch.unsqueeze(a[:, 3], dim=1), b[:, 3]) - torch.max(torch.unsqueeze(a[:, 1], 1), b[:, 1])\n",
    "\n",
    "#     iw = torch.clamp(iw, min=0)\n",
    "#     ih = torch.clamp(ih, min=0)\n",
    "\n",
    "#     ua = torch.unsqueeze((a[:, 2] - a[:, 0]) * (a[:, 3] - a[:, 1]), dim=1) + area - iw * ih\n",
    "\n",
    "#     ua = torch.clamp(ua, min=1e-8)\n",
    "\n",
    "#     intersection = iw * ih\n",
    "\n",
    "#     IoU = intersection / ua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "visible-phase",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.6416, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.4653, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.2818, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.1391, 0.0000, 0.0413, 0.0000],\n",
       "        [0.0000, 0.0250, 0.0000, 0.1352, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.2476, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.3848, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.4653, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.4239, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IoU = calc_iou(myan[0, :,:], annotation[:, :4])\n",
    "IoU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "perfect-angel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.8208, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.6389, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.4222, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.2258, 0.0000, 0.0714, 0.0000],\n",
       "        [0.0000, 0.0438, 0.0000, 0.2199, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.3777, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.5479, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.6389, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.5928, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IoU = paps_calc_iou(myan[0, :,:], annotation[:, :4])\n",
    "IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "announced-welsh",
   "metadata": {},
   "outputs": [],
   "source": [
    " IoU_max, IoU_argmax = torch.max(IoU, dim=1) # num_anchors x 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "surface-thumb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.8208, 1.6389, 1.4222, 1.2258, 1.2199, 1.3777, 1.5479, 1.6389, 1.5928,\n",
       "        1.0000])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IoU_max += 1\n",
    "IoU_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "valued-leone",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 3, 3, 3, 3, 3, 0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IoU_argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "found-cooler",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1., -1.],\n",
       "        [-1., -1.],\n",
       "        [-1., -1.],\n",
       "        [-1., -1.],\n",
       "        [-1., -1.],\n",
       "        [-1., -1.],\n",
       "        [-1., -1.],\n",
       "        [-1., -1.],\n",
       "        [-1., -1.],\n",
       "        [-1., -1.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = torch.ones([10,2]) * -1\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "certain-thirty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False,  True,  True, False, False, False, False,  True])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iou_threshold = 0.4\n",
    "torch.lt(IoU_max, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "latin-vegetarian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False,  True,  True,  True, False, False, False,  True])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.lt(IoU_max, iou_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "engaged-hearts",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1., -1.],\n",
       "        [-1., -1.],\n",
       "        [-1., -1.],\n",
       "        [-1., -1.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[torch.lt(IoU_max, iou_threshold), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bearing-terminology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1., -1.],\n",
       "        [-1., -1.],\n",
       "        [-1., -1.],\n",
       "        [ 0.,  0.],\n",
       "        [ 0.,  0.],\n",
       "        [-1., -1.],\n",
       "        [-1., -1.],\n",
       "        [-1., -1.],\n",
       "        [-1., -1.],\n",
       "        [ 0.,  0.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iou_threshold = 0.3\n",
    "targets[torch.lt(IoU_max, iou_threshold), :] = 0\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "selective-paradise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True, False, False, False,  True,  True,  True, False])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_indices = torch.ge(IoU_max, 0.4)\n",
    "positive_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "silver-tiger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_positive_anchors = positive_indices.sum()\n",
    "num_positive_anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "excess-saying",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[140.0000,  82.0000, 182.0000, 120.0000,   0.0000],\n",
       "        [140.0000,  82.0000, 182.0000, 120.0000,   0.0000],\n",
       "        [140.0000,  82.0000, 182.0000, 120.0000,   0.0000],\n",
       "        [140.0000,  82.0000, 182.0000, 120.0000,   0.0000],\n",
       "        [200.0000,  72.0000, 242.0000, 110.0000,   1.0000],\n",
       "        [200.0000,  72.0000, 242.0000, 110.0000,   1.0000],\n",
       "        [200.0000,  72.0000, 242.0000, 110.0000,   1.0000],\n",
       "        [200.0000,  72.0000, 242.0000, 110.0000,   1.0000],\n",
       "        [200.0000,  72.0000, 242.0000, 110.0000,   1.0000],\n",
       "        [113.5000, 137.2500, 137.0000, 159.7500,   0.0000]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assigned_annotations = annotation[IoU_argmax, :]\n",
    "assigned_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "marked-landing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  0.],\n",
       "        [ 0.,  0.],\n",
       "        [ 0.,  0.],\n",
       "        [ 0.,  0.],\n",
       "        [ 0.,  0.],\n",
       "        [-1., -1.],\n",
       "        [ 0.,  0.],\n",
       "        [ 0.,  0.],\n",
       "        [ 0.,  0.],\n",
       "        [ 0.,  0.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[positive_indices, :] = 0\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "regular-indianapolis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assigned_annotations[positive_indices, 4].long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "continental-patch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[positive_indices,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "integrated-cholesterol",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [-1., -1., -1., -1., -1., -1.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[:,assigned_annotations[positive_indices, 4].long()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "powerful-workstation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[positive_indices, assigned_annotations[positive_indices, 4].long()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "rolled-probe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[140.0000,  82.0000, 182.0000, 120.0000,   0.0000],\n",
       "        [140.0000,  82.0000, 182.0000, 120.0000,   0.0000],\n",
       "        [140.0000,  82.0000, 182.0000, 120.0000,   0.0000],\n",
       "        [140.0000,  82.0000, 182.0000, 120.0000,   0.0000],\n",
       "        [200.0000,  72.0000, 242.0000, 110.0000,   1.0000],\n",
       "        [200.0000,  72.0000, 242.0000, 110.0000,   1.0000],\n",
       "        [200.0000,  72.0000, 242.0000, 110.0000,   1.0000],\n",
       "        [200.0000,  72.0000, 242.0000, 110.0000,   1.0000],\n",
       "        [200.0000,  72.0000, 242.0000, 110.0000,   1.0000],\n",
       "        [113.5000, 137.2500, 137.0000, 159.7500,   0.0000]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assigned_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "unavailable-purse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True, False, False, False,  True,  True,  True, False])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "english-nutrition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assigned_annotations[positive_indices, 4].long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "historical-startup",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[[ True,  True, False, False, False, False,  True,  True,  True, False],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "central-intent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[[ True,  True, False, False, False, False,  True,  True,  True, False],[0, 0, 1, 1, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "worth-delhi",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  0.],\n",
       "        [ 0.,  0.],\n",
       "        [ 0.,  0.],\n",
       "        [ 0.,  0.],\n",
       "        [ 0.,  0.],\n",
       "        [-1., -1.],\n",
       "        [ 0.,  0.],\n",
       "        [ 0.,  0.],\n",
       "        [ 0.,  0.],\n",
       "        [ 0.,  0.]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "serial-scenario",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 0.,  0.],\n",
       "        [ 0.,  0.],\n",
       "        [-1., -1.],\n",
       "        [ 0.,  1.],\n",
       "        [ 0.,  1.],\n",
       "        [ 0.,  1.],\n",
       "        [ 0.,  0.]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[positive_indices, assigned_annotations[positive_indices, 4].long()] = 1\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparative-portrait",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "stuffed-violence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2500, 0.2500],\n",
       "        [0.2500, 0.2500],\n",
       "        [0.2500, 0.2500],\n",
       "        [0.2500, 0.2500],\n",
       "        [0.2500, 0.2500],\n",
       "        [0.2500, 0.2500],\n",
       "        [0.2500, 0.2500],\n",
       "        [0.2500, 0.2500],\n",
       "        [0.2500, 0.2500],\n",
       "        [0.2500, 0.2500]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 0.25\n",
    "alpha_factor = torch.ones(targets.shape) * alpha\n",
    "alpha_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "future-hartford",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2500, 0.7500],\n",
       "        [0.2500, 0.7500],\n",
       "        [0.2500, 0.7500],\n",
       "        [0.7500, 0.7500],\n",
       "        [0.7500, 0.7500],\n",
       "        [0.7500, 0.7500],\n",
       "        [0.7500, 0.2500],\n",
       "        [0.7500, 0.2500],\n",
       "        [0.7500, 0.2500],\n",
       "        [0.7500, 0.7500]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_factor = torch.where(torch.eq(targets, 1.), alpha_factor, 1. - alpha_factor)\n",
    "alpha_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "reserved-skating",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification =torch.rand([10,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "impressive-afghanistan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8030, 0.1335],\n",
       "        [0.2506, 0.5786],\n",
       "        [0.4404, 0.4075],\n",
       "        [0.4682, 0.4669],\n",
       "        [0.3712, 0.5615],\n",
       "        [0.2450, 0.8486],\n",
       "        [0.0079, 0.2464],\n",
       "        [0.2813, 0.4184],\n",
       "        [0.7936, 0.5294],\n",
       "        [0.0708, 0.9235]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "focal_weight = torch.where(torch.eq(targets, 1.), 1. - classification, classification)\n",
    "focal_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "satellite-height",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.6121e-01, 1.3358e-02],\n",
       "        [1.5695e-02, 2.5105e-01],\n",
       "        [4.8486e-02, 1.2452e-01],\n",
       "        [1.6440e-01, 1.6352e-01],\n",
       "        [1.0333e-01, 2.3644e-01],\n",
       "        [4.5012e-02, 5.4014e-01],\n",
       "        [4.6710e-05, 1.5181e-02],\n",
       "        [5.9366e-02, 4.3767e-02],\n",
       "        [4.7230e-01, 7.0064e-02],\n",
       "        [3.7567e-03, 6.3964e-01]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma=2\n",
    "focal_weight = alpha_factor * torch.pow(focal_weight, gamma)\n",
    "focal_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "identical-progressive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.6247,  0.1432],\n",
       "        [ 0.2884,  0.8641],\n",
       "        [ 0.5805,  0.5234],\n",
       "        [ 0.6315,  0.6291],\n",
       "        [ 0.4639,  0.8243],\n",
       "        [-0.8445,  3.6120],\n",
       "        [ 0.0079,  0.2829],\n",
       "        [ 0.3304,  0.5420],\n",
       "        [ 1.5777,  0.7537],\n",
       "        [ 0.0734,  2.5704]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bce = -(targets * torch.log(classification) + (1.0 - targets) * torch.log(1.0 - classification))\n",
    "bce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "capital-albert",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.6192e-01,  1.9135e-03],\n",
       "        [ 4.5270e-03,  2.1693e-01],\n",
       "        [ 2.8147e-02,  6.5169e-02],\n",
       "        [ 1.0381e-01,  1.0287e-01],\n",
       "        [ 4.7932e-02,  1.9491e-01],\n",
       "        [-3.8015e-02,  1.9510e+00],\n",
       "        [ 3.7009e-07,  4.2952e-03],\n",
       "        [ 1.9613e-02,  2.3721e-02],\n",
       "        [ 7.4516e-01,  5.2810e-02],\n",
       "        [ 2.7575e-04,  1.6442e+00]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_loss = focal_weight * bce\n",
    "cls_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "occupied-incentive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 0.,  0.],\n",
       "        [ 0.,  0.],\n",
       "        [-1., -1.],\n",
       "        [ 0.,  1.],\n",
       "        [ 0.,  1.],\n",
       "        [ 0.,  1.],\n",
       "        [ 0.,  0.]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ethical-graphics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.8208],\n",
       "        [1.6389],\n",
       "        [1.4222],\n",
       "        [1.2258],\n",
       "        [1.2199],\n",
       "        [1.3777],\n",
       "        [1.5479],\n",
       "        [1.6389],\n",
       "        [1.5928],\n",
       "        [1.0000]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IoU_max.unsqueeze(dim=0).transpose(1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "charitable-wrist",
   "metadata": {},
   "outputs": [],
   "source": [
    "IoU_max -= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "hollow-shoulder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.8208],\n",
       "        [1.6389],\n",
       "        [1.4222],\n",
       "        [1.2258],\n",
       "        [1.2199],\n",
       "        [1.3777],\n",
       "        [1.5479],\n",
       "        [1.6389],\n",
       "        [1.5928],\n",
       "        [1.0000]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IoU_max.unsqueeze(dim=0).transpose(1,0) + 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "binding-teach",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3208, 0.2500],\n",
       "        [1.1389, 0.2500],\n",
       "        [0.9222, 0.2500],\n",
       "        [0.2500, 0.2500],\n",
       "        [0.2500, 0.2500],\n",
       "        [0.2500, 0.2500],\n",
       "        [0.2500, 1.0479],\n",
       "        [0.2500, 1.1389],\n",
       "        [0.2500, 1.0928],\n",
       "        [0.2500, 0.2500]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_weight = targets * (IoU_max.unsqueeze(dim=0).transpose(1,0))\n",
    "f_weight = torch.clamp(f_weight, min=0.25)\n",
    "f_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "digital-dakota",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (10) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-95d6c137d1b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtargets\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mIoU_max\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (10) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "targets ** IoU_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "adequate-reserve",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.6192e-01, 1.9135e-03],\n",
       "        [4.5270e-03, 2.1693e-01],\n",
       "        [2.8147e-02, 6.5169e-02],\n",
       "        [1.0381e-01, 1.0287e-01],\n",
       "        [4.7932e-02, 1.9491e-01],\n",
       "        [0.0000e+00, 0.0000e+00],\n",
       "        [3.7009e-07, 4.2952e-03],\n",
       "        [1.9613e-02, 2.3721e-02],\n",
       "        [7.4516e-01, 5.2810e-02],\n",
       "        [2.7575e-04, 1.6442e+00]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_loss = torch.where(torch.ne(targets, -1.0), cls_loss, torch.zeros(cls_loss.shape))\n",
    "cls_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "senior-aviation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_positive_anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "exceptional-glasgow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.5182)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "monthly-teacher",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.clamp(num_positive_anchors.float(), min=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "uniform-motion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5864)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_loss.sum()/torch.clamp(num_positive_anchors.float(), min=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "necessary-ocean",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_widths  = myan[0,:, 2] - myan[0,:, 0]\n",
    "anchor_heights = myan[0,:, 3] - myan[0,:, 1]\n",
    "anchor_ctr_x   = myan[0,:, 0] + 0.5 * anchor_widths\n",
    "anchor_ctr_y   = myan[0,:, 1] + 0.5 * anchor_heights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "close-engineering",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_widths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-laptop",
   "metadata": {},
   "outputs": [],
   "source": [
    "assigned_annotations = assigned_annotations[positive_indices, :4]\n",
    "\n",
    "anchor_widths_pi = anchor_widths[positive_indices]\n",
    "anchor_heights_pi = anchor_heights[positive_indices]\n",
    "anchor_ctr_x_pi = anchor_ctr_x[positive_indices]\n",
    "anchor_ctr_y_pi = anchor_ctr_y[positive_indices]\n",
    "\n",
    "gt_widths  = assigned_annotations[:, 2] - assigned_annotations[:, 0]\n",
    "gt_heights = assigned_annotations[:, 3] - assigned_annotations[:, 1]\n",
    "gt_ctr_x   = assigned_annotations[:, 0] + 0.5 * gt_widths\n",
    "gt_ctr_y   = assigned_annotations[:, 1] + 0.5 * gt_heights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yellow-trailer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip widths to 1\n",
    "gt_widths  = torch.clamp(gt_widths, min=1)\n",
    "gt_heights = torch.clamp(gt_heights, min=1)\n",
    "\n",
    "targets_dx = (gt_ctr_x - anchor_ctr_x_pi) / anchor_widths_pi\n",
    "targets_dy = (gt_ctr_y - anchor_ctr_y_pi) / anchor_heights_pi\n",
    "targets_dw = torch.log(gt_widths / anchor_widths_pi)\n",
    "targets_dh = torch.log(gt_heights / anchor_heights_pi)\n",
    "\n",
    "targets = torch.stack((targets_dx, targets_dy, targets_dw, targets_dh))\n",
    "targets = targets.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleased-settlement",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-phenomenon",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = targets/torch.Tensor([[0.1, 0.1, 0.2, 0.2]])\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suitable-binding",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression = torch.rand([10, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technical-hampton",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "targets = targets/torch.Tensor([[0.1, 0.1, 0.2, 0.2]])\n",
    "\n",
    "negative_indices = 1 + (~positive_indices)\n",
    "\n",
    "regression_diff = torch.abs(targets - regression[positive_indices, :])\n",
    "\n",
    "#                 change the beta value from 1/9 to 1.0\n",
    "regression_loss = torch.where(\n",
    "    torch.le(regression_diff, 1.0),\n",
    "    0.5 * torch.pow(regression_diff, 2),\n",
    "    regression_diff - 0.5\n",
    ")\n",
    "regression_losses.append(regression_loss.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-hours",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-destiny",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn([4,6])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twenty-entrepreneur",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[[1,1,1,0,1],[2,3,2,4,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twenty-aircraft",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([\n",
    "    [1,2,3],[4,5,6.]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "returning-albert",
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-buddy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 마스크 배열을 이용하여 True 값만 추출\n",
    "# t[t > 3]\n",
    "# : tensor([4., 5., 6.])\n",
    "\n",
    "# # 슬라이스를 이용하여 일괄 대입\n",
    "# t[:, 1] = 10\n",
    "\n",
    "# # 마스크 배열을 사용하여 일괄 대입\n",
    "# t[t > 5] = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "completed-seminar",
   "metadata": {},
   "outputs": [],
   "source": [
    "t[t > 3] = 1\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collected-egypt",
   "metadata": {},
   "outputs": [],
   "source": [
    "t[:, 1] = 10\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-devil",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(x)\n",
    "x = torch.tensor([[0.4898, 0.2505, 0.6500],\n",
    "        [0.0976, 0.4117, 0.9705],\n",
    "        [0.7069, 0.0546, 0.7824],\n",
    "        [0.4921, 0.9863, 0.3936]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "declared-modem",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1,3])\n",
    "b = torch.tensor([1,2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "third-newfoundland",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[np.ix_(a,b)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becoming-wrapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.arange(35).reshape(5, 7)\n",
    "# y = [[0, 1, 2, 3, 4, 5, 6],\n",
    "#    [7, 8, 9, 10, 11, 12, 13],\n",
    "#    [14, 15, 16, 17, 18, 19, 20],\n",
    "#    [21, 22, 23, 24, 25, 26, 27],\n",
    "#    [28, 29, 30, 31, 32, 33, 34]]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hazardous-registration",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "b = y > 20\n",
    "b\n",
    "# print(y[b]) #[21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-links",
   "metadata": {},
   "outputs": [],
   "source": [
    "b[: , 5] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear-china",
   "metadata": {},
   "outputs": [],
   "source": [
    "y[b[ : , 5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cultural-cedar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b[: , 5] = [False False False True True]\n",
    "print(y[b[ : , 5]])\n",
    "# [[21 22 23 24 25 26 27],\n",
    "#  [28 29 30 31 32 33 34]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-swift",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(30).reshape(2, 3, 5)\n",
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "victorian-spouse",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-welcome",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.arange(15).reshape(3, 5)\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expanded-bishop",
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = np.array([True, True, False])\n",
    "b2 = np.array([False, True, False, True, True])\n",
    "\n",
    "print(f[b1, :])\n",
    "# [[0 1 2 3 4]\n",
    "#  [5 6 7 8 9]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-ebony",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f[:, b2])\n",
    "# [[ 1  3  4]\n",
    "#  [ 6  8  9]\n",
    "#  [11 13 14]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-alpha",
   "metadata": {},
   "outputs": [],
   "source": [
    "f[b1, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virtual-elephant",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[ 0,  1,  2,  3],\n",
    "       [ 4,  5,  6,  7],\n",
    "       [ 8,  9, 10, 11]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worthy-circus",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[1:, [2,0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "judicial-championship",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[np.array([[1,2]]), np.array([2,0,1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peripheral-catch",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.arange(35).reshape(5,7)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-pledge",
   "metadata": {},
   "outputs": [],
   "source": [
    "y[np.array([0,2,4]), np.array([0,1,2])] = -1\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radio-tomorrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "y[[0,2,4], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirmed-singapore",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_retina",
   "language": "python",
   "name": "pytorch_retina"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
